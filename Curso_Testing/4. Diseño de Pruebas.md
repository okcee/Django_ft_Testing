# Diseño de Pruebas para Testing
El proceso de testing se realiza de forma iterativa, permitiendo la identificación y corrección de defectos de manera continua a lo largo del ciclo de vida del software. Las pruebas no son uniformes, sino que se adaptan según el nivel de testing que se esté llevando a cabo.

## Test Case
Un Caso de Prueba (Test Case) es un conjunto específico de acciones que se ejecutan sobre un componente o funcionalidad del software para verificar un comportamiento particular. Su objetivo principal es determinar si la funcionalidad bajo prueba se comporta según lo esperado.  
Un caso de prueba típicamente incluye los siguientes elementos:  
- Identificador único: Una referencia para identificar el caso de prueba.  
- Título o descripción: Una breve descripción del objetivo del caso de prueba.  
- Precondiciones: Las condiciones que deben cumplirse antes de ejecutar el caso de prueba (por ejemplo, datos de prueba específicos, el sistema en un estado particular).  
- Pasos: La secuencia detallada de acciones que se deben realizar.  
- Datos de prueba: Los valores de entrada específicos que se utilizarán durante la ejecución de los pasos.  
- Resultado esperado: El resultado que se espera obtener si la funcionalidad funciona correctamente.  
- Resultado real: El resultado que se obtiene al ejecutar el caso de prueba.  
- Estado: Indica si el caso de prueba pasó (Pass), falló (Fail), está bloqueado (Blocked), etc.  
- Prioridad: Indica la importancia del caso de prueba (por ejemplo, alta, media, baja).  
- Severidad (en caso de fallo): Indica el impacto del defecto encontrado (por ejemplo, crítico, mayor, menor).  


## Niveles de Testing y sus Diseños de Prueba
A continuación, se describen los niveles de testing comunes y los enfoques de diseño de pruebas típicamente asociados a cada uno:

### 1. Pruebas Unitarias (Unit Testing)
* **Objetivo:** Verificar la funcionalidad de unidades individuales de código (funciones, métodos, clases).
* **Diseños de Prueba Comunes:**
    * **Pruebas de Caja Blanca (White-Box Testing):** Se basa en el conocimiento de la estructura interna del código.
        * **Cobertura de Sentencias:** Asegurar que cada línea de código se ejecute al menos una vez.
        * **Cobertura de Decisiones (o Ramas):** Asegurar que cada resultado posible de una condición (verdadero/falso) se pruebe.
        * **Cobertura de Caminos:** Asegurar que se prueben todos los caminos de ejecución posibles a través de una unidad.
        * **Cobertura de Condiciones:** Asegurar que todas las condiciones lógicas dentro de una decisión se prueben en todas sus combinaciones posibles.
    * **Pruebas de Caja Negra (Black-Box Testing) (menos común a nivel unitario):** Se centra en la funcionalidad desde la perspectiva del usuario, sin conocer la estructura interna.
        * **Particiones de Equivalencia:** Dividir los datos de entrada en grupos equivalentes y probar un valor representativo de cada grupo.
        * **Análisis de Valores Límite:** Probar los valores en los bordes de las particiones de equivalencia.

### 2. Pruebas de Integración (Integration Testing)
* **Objetivo:** Verificar la interacción y comunicación entre diferentes unidades o componentes del software.
* **Diseños de Prueba Comunes:**
    * **Pruebas Top-Down:** Comenzar probando los módulos de alto nivel y avanzar hacia los módulos de bajo nivel, utilizando stubs (simuladores) para los módulos aún no desarrollados.
    * **Pruebas Bottom-Up:** Comenzar probando los módulos de bajo nivel y avanzar hacia los módulos de alto nivel, utilizando drivers (controladores) para invocar los módulos probados.
    * **Pruebas Big-Bang:** Integrar todos los componentes a la vez y luego probarlos. (Menos recomendable debido a la dificultad para aislar fallos).
    * **Pruebas Incrementales (Sandwich Testing):** Combinación de enfoques top-down y bottom-up, probando capas intermedias y avanzando hacia arriba y hacia abajo.
    * **Pruebas Basadas en Escenarios:** Diseñar pruebas basadas en casos de uso o flujos de trabajo del usuario para verificar la interacción entre componentes.

### 3. Pruebas de Sistema (System Testing)
* **Objetivo:** Evaluar el sistema completo integrado, verificando que cumple con los requisitos funcionales y no funcionales.
* **Diseños de Prueba Comunes:**
    * **Pruebas Funcionales:** Verificar que el sistema realiza las funciones esperadas. Se utilizan técnicas de caja negra como:
        * **Particiones de Equivalencia**
        * **Análisis de Valores Límite**
        * **Tablas de Decisión:** Modelar la lógica compleja de decisiones y probar todas las combinaciones posibles.
        * **Pruebas Basadas en Casos de Uso:** Diseñar pruebas directamente a partir de los casos de uso del sistema.
        * **Pruebas Basadas en Especificaciones:** Diseñar pruebas directamente a partir de los documentos de requisitos.
    * **Pruebas No Funcionales:** Evaluar aspectos como:
        * **Pruebas de Rendimiento (Performance Testing):** Evaluar la capacidad de respuesta, estabilidad y uso de recursos del sistema bajo diferentes cargas.
        * **Pruebas de Carga (Load Testing):** Simular cargas de usuario esperadas.
        * **Pruebas de Estrés (Stress Testing):** Llevar el sistema más allá de sus límites para identificar puntos débiles.
        * **Pruebas de Usabilidad (Usability Testing):** Evaluar la facilidad de uso del sistema por parte de los usuarios finales.
        * **Pruebas de Seguridad (Security Testing):** Identificar vulnerabilidades y asegurar la protección de datos.
        * **Pruebas de Compatibilidad (Compatibility Testing):** Verificar el funcionamiento del sistema en diferentes entornos (navegadores, sistemas operativos, dispositivos).
        * **Pruebas de Confiabilidad (Reliability Testing):** Evaluar la capacidad del sistema para funcionar sin fallos durante un período específico.
        * **Pruebas de Recuperación (Recovery Testing):** Verificar la capacidad del sistema para recuperarse de fallos o errores.

### 4. Pruebas de Implementación (Deployment/Installation Testing)

* **Objetivo:** Verificar que el software se puede instalar, configurar y desplegar correctamente en los entornos previstos (pruebas, pre-producción, producción).
* **Diseños de Prueba Comunes:**
    * **Pruebas de Instalación:** Verificar la correcta instalación del software en diferentes sistemas operativos, configuraciones de hardware y software. Esto incluye probar diferentes métodos de instalación (GUI, línea de comandos, silenciosa).
    * **Pruebas de Configuración:** Verificar que el software se puede configurar correctamente según los requisitos del entorno.
    * **Pruebas de Migración de Datos:** Si aplica, verificar que los datos se migran correctamente desde versiones anteriores o sistemas existentes.
    * **Pruebas de Despliegue:** Verificar el correcto despliegue del software en los servidores o plataformas de destino.
    * **Pruebas de Desinstalación:** Verificar que el software se puede desinstalar completamente sin dejar rastros no deseados.
    * **Pruebas de Rollback:** Verificar la capacidad de revertir a una versión anterior en caso de fallos durante la implementación.
    * **Pruebas de Licenciamiento:** Verificar que el sistema de licenciamiento funciona correctamente.

### 5. Pruebas de Aceptación (Acceptance Testing)

* **Objetivo:** Obtener la aprobación formal del cliente o usuario final de que el sistema cumple con sus necesidades y expectativas.
* **Diseños de Prueba Comunes:**
    * **Pruebas de Aceptación por el Usuario (UAT - User Acceptance Testing):** Realizadas por los usuarios finales en un entorno que simula el entorno de producción. Se basan en escenarios de uso reales.
    * **Pruebas de Aceptación Operacional (OAT - Operational Acceptance Testing):** Verificar la preparación del sistema para su operación y mantenimiento (instalación, copias de seguridad, recuperación, etc.).
    * **Pruebas Alfa y Beta:**
        * **Pruebas Alfa:** Realizadas internamente por el equipo de desarrollo o testers en un entorno controlado antes de la liberación externa.
        * **Pruebas Beta:** Realizadas por usuarios reales fuera del equipo de desarrollo en su propio entorno.

### 6. Pruebas de Regresión (Regression Testing)
* **Objetivo:** Asegurar que los cambios realizados en el software (corrección de errores, nuevas funcionalidades, refactorización) no hayan introducido nuevos defectos o afectado negativamente a la funcionalidad existente.
* **Diseños de Prueba Comunes:**
    * **Re-ejecución de Casos de Prueba Fallidos:** Volver a ejecutar los casos de prueba que fallaron en ciclos de prueba anteriores después de que se hayan realizado las correcciones.
    * **Selección de Casos de Prueba:** Elegir un subconjunto de casos de prueba existentes que cubran las áreas del software que han sido modificadas o que podrían verse afectadas por los cambios. La selección puede basarse en:
        * **Análisis de Impacto:** Identificar las áreas del software que probablemente se vean afectadas por los cambios.
        * **Casos de Prueba de Alto Riesgo:** Priorizar la ejecución de casos de prueba que cubren funcionalidades críticas o propensas a errores.
        * **Casos de Prueba Recientes:** Incluir casos de prueba que fallaron recientemente.
        * **Casos de Prueba de Funcionalidades Relacionadas:** Probar funcionalidades que interactúan con las áreas modificadas.
    * **Automatización:** La automatización es fundamental para las pruebas de regresión debido a la necesidad de ejecutarlas con frecuencia.

## Consideraciones Adicionales para el Diseño de Pruebas

* **Cobertura:** Asegurar una cobertura adecuada de los requisitos y funcionalidades del software.
* **Técnicas de Diseño:** Seleccionar las técnicas de diseño de pruebas más apropiadas para cada nivel y tipo de prueba.
* **Datos de Prueba:** Planificar y crear datos de prueba relevantes y representativos.
* **Automatización:** Identificar pruebas que puedan ser automatizadas para mejorar la eficiencia y la repetibilidad.
* **Gestión de Casos de Prueba:** Utilizar herramientas para crear, gestionar, ejecutar y rastrear los casos de prueba.
* **Trazabilidad:** Mantener la trazabilidad entre los requisitos, los casos de prueba y los defectos encontrados.

La adaptación de los diseños de prueba a cada nivel de testing es crucial para asegurar una cobertura efectiva y eficiente, maximizando la probabilidad de identificar defectos en las etapas más tempranas del ciclo de vida del desarrollo del software.
Todo el proceso de testing se realiza por iteraciones y no de una sola vez.  
Las pruebas tienen ciertos diseños, no todas son iguales, estas se adaptan según el nivel de testing realizado.  


